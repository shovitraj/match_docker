{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nlp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nlp.py\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from tika import parser\n",
    "import string\n",
    "import utils\n",
    "\n",
    "# ps = nltk.PorterStemmer()\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    punct = \"\".join(string.punctuation)\n",
    "    text = \"\".join([char.lower() for char in text if char not in punct])\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove all tokens that are not alphabetic\n",
    "    wordsisalpha = [word for word in tokens if word.isalpha()]\n",
    "    #stemmed = [ps.stem(word) for word in wordsisalpha]\n",
    "    final_token = [word for word in wordsisalpha if word not in sw]\n",
    "    word_count = Counter(final_token)\n",
    "    return word_count\n",
    "\n",
    "def cosSimilarity(x, y):\n",
    "    dot_product = np.dot(x,y)\n",
    "    normx = np.linalg.norm(x)\n",
    "    normy = np.linalg.norm(y)\n",
    "    similarity = dot_product / (normx * normy)\n",
    "    return similarity\n",
    "\n",
    "def Similarity(dict1, dict2):\n",
    "    words_list = []\n",
    "    for key in dict1:\n",
    "        words_list.append(key)\n",
    "    for key in dict2:\n",
    "        words_list.append(key)\n",
    "    list_size = len(words_list)\n",
    "    \n",
    "    v1 = np.zeros(list_size, dtype= np.int)\n",
    "    v2 = np.zeros(list_size, dtype= np.int)\n",
    "    \n",
    "    i = 0\n",
    "    for (key) in words_list:\n",
    "        v1[i] = dict1.get(key,0)\n",
    "        v2[i] = dict2.get(key,0)\n",
    "        i = i+1\n",
    "    return cosSimilarity(v1, v2)\n",
    "\n",
    "def clean(text): \n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('_', '')\n",
    "    text = text.replace('●', '')\n",
    "    text = text.replace('•', '')\n",
    "    return text\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "revolutionary-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sklearn_cosine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sklearn_cosine.py\n",
    "\n",
    "\n",
    "def sk_cos_similarity(text_list):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    cv = CountVectorizer()\n",
    "    count_matrix = cv.fit_transform(text_list)\n",
    "    matchPercentage=cosine_similarity(count_matrix)[0][1]*100\n",
    "    matchPercentage= round(matchPercentage, 2)\n",
    "    return sk_cos_similarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "retired-douglas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jams.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile jams.py\n",
    "\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "from nlp import preprocess, Similarity, clean\n",
    "\n",
    "# from spacy_similarity import spacy_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn_cosine import sk_cos_similarity\n",
    "import streamlit as st \n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "import spacy_streamlit\n",
    "\n",
    "hide_streamlit_style = \"\"\"\n",
    "            <style>\n",
    "            #MainMenu {visibility: hidden;}\n",
    "            footer {visibility: hidden;}\n",
    "            </style>\n",
    "            \"\"\"\n",
    "st.markdown(hide_streamlit_style, unsafe_allow_html=True)\n",
    "    \n",
    "\n",
    "\n",
    "def_job = \"Paste your job description here.\"\n",
    "def_resume = \"Paste your resume here.\"\n",
    "\n",
    "st.sidebar.title('Which Similarity')\n",
    "select_similarity = st.sidebar.selectbox('Select one',\n",
    "                                         ['Home Brew Cosine', 'Spacy Similairty','Sklearn Cosine', 'BERT Cosine'])\n",
    "st.title('Resume Match')\n",
    "\n",
    "job = st.text_area('Paste your Job Description', def_job)\n",
    "resume = st.text_area('Paste your Resume', def_resume)\n",
    "\n",
    "nlp=spacy.load('en_core_web_md')\n",
    "\n",
    "doc1 = nlp(job)\n",
    "doc2 = nlp(resume)\n",
    "\n",
    "\n",
    "### 'Home Brew Cosine'\n",
    "\n",
    "pp_job = preprocess(job)\n",
    "pp_resume = preprocess(resume)\n",
    "\n",
    "\n",
    "matchPercentage = np.round((Similarity(pp_job, pp_resume)*100),2)\n",
    "\n",
    "\n",
    "### Cosine Similarity\n",
    "    \n",
    "sk_job = clean(job)\n",
    "sk_resume = clean(resume)\n",
    "\n",
    "text_list = [sk_job, sk_resume]\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text_list)\n",
    "matchPercentage_sk=cosine_similarity(count_matrix)[0][1]*100\n",
    "matchPercentage_sk= round(matchPercentage_sk, 2)\n",
    "\n",
    "### Spacy built in Similarity\n",
    "matchPercentage_spacy= round(doc1.similarity(doc2),2)*100\n",
    "\n",
    "\n",
    "if select_similarity == \"Home Brew Cosine\":\n",
    "    if len(job) != 0 and len(resume) != 0:\n",
    "        st.write(\"Your Resume matched\", matchPercentage, '% with the job description')    \n",
    "if select_similarity == \"Sklearn Cosine\":\n",
    "    if len(job) != 0 and len(resume) != 0:\n",
    "        st.write(\"Your Resume matched\", matchPercentage_sk, '% with the job description')\n",
    "if select_similarity=='Spacy Similarity':\n",
    "    \n",
    "    if len(job) != 0 and len(resume) != 0:\n",
    "        st.write(\"Your Resume matched\", matchPercentage_spacy, '% with the job description')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "conventional-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cosine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cosine.py\n",
    "\n",
    "import utils\n",
    "import streamlit as st \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "job = st.text_area(\"This is a job description.\", 'Paste your job description here.')\n",
    "resume = st.text_area(\"This is a resume.\", 'Paste your resume here')\n",
    "\n",
    "job = job.lower()\n",
    "job = job.replace('\\n', '')\n",
    "job = job.replace('_', '')\n",
    "\n",
    "resume = resume.lower()\n",
    "resume = resume.replace('\\n', '')\n",
    "resume = resume.replace('_', '')\n",
    "\n",
    "text_list = [job, resume]\n",
    "\n",
    "    \n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text_list)\n",
    "matchPercentage=cosine_similarity(count_matrix)[0][1]*100\n",
    "matchPercentage= round(matchPercentage, 2)\n",
    "\n",
    "st.write(matchPercentage)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "enhanced-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spacytest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spacytest.py\n",
    "\n",
    "import streamlit as st \n",
    "import spacy\n",
    "import spacy_streamlit\n",
    "\n",
    "nlp=spacy.load('en_core_web_md')\n",
    "\n",
    "\n",
    "job = st.text_area(\"This is a job description.\", 'Paste your job description here.')\n",
    "resume = st.text_area(\"This is a resume.\", 'Paste your resume here')\n",
    "\n",
    "job = job.lower()\n",
    "job = job.replace('\\n', '')\n",
    "job = job.replace('_', '')\n",
    "\n",
    "resume = resume.lower()\n",
    "resume = resume.replace('\\n', '')\n",
    "resume = resume.replace('_', '')\n",
    "\n",
    "### Spacy built in Similarity\n",
    "doc1 = nlp(job)\n",
    "doc2 = nlp(resume)\n",
    "matchPercentage_spacy= round(doc1.similarity(doc2),2)*100\n",
    "\n",
    "st.write(\"Your Resume matched\", matchPercentage_spacy, '% with the job description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-citizen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
